{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Neuromorphic Classifier - Gradio Demo"
      ],
      "metadata": {
        "id": "ymYvRc7bOseY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "QDf-YJtjOxAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio -q\n",
        "!pip install snntorch -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96xgMiNyQ3sW",
        "outputId": "745916fa-9788-46c3-9149-7d7f4d7bb836"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://github.com/MatTheTab/neuromorphic_classifier/raw/refs/heads/main/models/neuromorphic_delta_model.pth\"\n",
        "!wget \"https://github.com/MatTheTab/neuromorphic_classifier/raw/refs/heads/main/models/neuromorphic_rate_model.pth\"\n",
        "!wget \"https://github.com/MatTheTab/neuromorphic_classifier/raw/refs/heads/main/models/neuromorphic_temporal_model.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KalbUwkVUJZG",
        "outputId": "c572a366-64a4-4e25-ccea-cc1dd783bd98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-26 13:32:54--  https://github.com/MatTheTab/neuromorphic_classifier/raw/refs/heads/main/models/neuromorphic_delta_model.pth\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MatTheTab/neuromorphic_classifier/refs/heads/main/models/neuromorphic_delta_model.pth [following]\n",
            "--2025-02-26 13:32:55--  https://raw.githubusercontent.com/MatTheTab/neuromorphic_classifier/refs/heads/main/models/neuromorphic_delta_model.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14506 (14K) [application/octet-stream]\n",
            "Saving to: ‘neuromorphic_delta_model.pth’\n",
            "\n",
            "neuromorphic_delta_ 100%[===================>]  14.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-26 13:32:55 (57.0 MB/s) - ‘neuromorphic_delta_model.pth’ saved [14506/14506]\n",
            "\n",
            "--2025-02-26 13:32:55--  https://github.com/MatTheTab/neuromorphic_classifier/raw/refs/heads/main/models/neuromorphic_rate_model.pth\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MatTheTab/neuromorphic_classifier/refs/heads/main/models/neuromorphic_rate_model.pth [following]\n",
            "--2025-02-26 13:32:55--  https://raw.githubusercontent.com/MatTheTab/neuromorphic_classifier/refs/heads/main/models/neuromorphic_rate_model.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14478 (14K) [application/octet-stream]\n",
            "Saving to: ‘neuromorphic_rate_model.pth’\n",
            "\n",
            "neuromorphic_rate_m 100%[===================>]  14.14K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-26 13:32:55 (90.6 MB/s) - ‘neuromorphic_rate_model.pth’ saved [14478/14478]\n",
            "\n",
            "--2025-02-26 13:32:55--  https://github.com/MatTheTab/neuromorphic_classifier/raw/refs/heads/main/models/neuromorphic_temporal_model.pth\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MatTheTab/neuromorphic_classifier/refs/heads/main/models/neuromorphic_temporal_model.pth [following]\n",
            "--2025-02-26 13:32:56--  https://raw.githubusercontent.com/MatTheTab/neuromorphic_classifier/refs/heads/main/models/neuromorphic_temporal_model.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14590 (14K) [application/octet-stream]\n",
            "Saving to: ‘neuromorphic_temporal_model.pth’\n",
            "\n",
            "neuromorphic_tempor 100%[===================>]  14.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-26 13:32:56 (116 MB/s) - ‘neuromorphic_temporal_model.pth’ saved [14590/14590]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from IPython.display import HTML\n",
        "import snntorch as snn\n",
        "from snntorch import spikegen\n",
        "from snntorch import surrogate\n",
        "import torch.nn.functional as F\n",
        "import snntorch.spikeplot as splt\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tempfile"
      ],
      "metadata": {
        "id": "NZKxxdzoQ612"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables"
      ],
      "metadata": {
        "id": "byho7PZSOzeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "IMAGE_REPITIONS = 4\n",
        "EPOCHS = 30\n",
        "SPIKE_GRAD = surrogate.fast_sigmoid(slope=25) #\n",
        "BETA = 0.5\n",
        "NUM_STEPS = 10\n",
        "GAIN = 0.5\n",
        "THRESHOLD_LATENCY = 1e-4\n",
        "TAU = 0.9\n",
        "THRESHOLD_DELTA = 0.5\n",
        "NUM_CLASSES = 10"
      ],
      "metadata": {
        "id": "A6pzaBMAR_p2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redefinitions"
      ],
      "metadata": {
        "id": "gZiI-R-VO2Jd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)"
      ],
      "metadata": {
        "id": "OdyH0AIeSvIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df6de46d-d1d5-46ae-9916-32747f88a43c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 485kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.45MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.82MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuromorphic_Net(nn.Module):\n",
        "    '''\n",
        "    A spiking neural network (SNN) model using leaky integrate-and-fire (LIF) neurons.\n",
        "\n",
        "    Parameters:\n",
        "    input_shape (tuple): Shape of the input data (batch_size, channels, height, width).\n",
        "    num_classes (int): Number of output classes for classification.\n",
        "\n",
        "    Attributes:\n",
        "    conv1 (nn.Conv2d): First convolutional layer.\n",
        "    lif1 (snn.Leaky): First LIF layer.\n",
        "    conv2 (nn.Conv2d): Second convolutional layer.\n",
        "    lif2 (snn.Leaky): Second LIF layer.\n",
        "    conv3 (nn.Conv2d): Third convolutional layer.\n",
        "    lif3 (snn.Leaky): Third LIF layer.\n",
        "    output (nn.Linear): Fully connected output layer.\n",
        "    lif4 (snn.Leaky): Fourth LIF layer.\n",
        "\n",
        "    Methods:\n",
        "    get_covnolution_output(): Computes the flattened output size after convolutional layers.\n",
        "    reset_states(): Resets the membrane potentials of LIF layers.\n",
        "    forward(x): Performs a forward pass through the network.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: Output spike activity of the final layer.\n",
        "    '''\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "        self.in_channels = input_shape[1]\n",
        "        self.conv1 = nn.Conv2d(self.in_channels, 4, 3)\n",
        "        self.lif1 = snn.Leaky(beta=BETA, spike_grad=SPIKE_GRAD)\n",
        "        self.conv2 = nn.Conv2d(4, 8, 3)\n",
        "        self.lif2 = snn.Leaky(beta=BETA, spike_grad=SPIKE_GRAD)\n",
        "        self.conv3 = nn.Conv2d(8, 16, 3)\n",
        "        self.lif3 = snn.Leaky(beta=BETA, spike_grad=SPIKE_GRAD)\n",
        "        self.output = nn.Linear(self.get_covnolution_output(), self.num_classes)\n",
        "        self.lif4 = snn.Leaky(beta=BETA, spike_grad=SPIKE_GRAD)\n",
        "\n",
        "    def get_covnolution_output(self):\n",
        "        dummy_input = torch.rand(*self.input_shape)\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "        cur1 = F.max_pool2d(self.conv1(dummy_input), 2)\n",
        "        spk1, mem1 = self.lif1(cur1, mem1)\n",
        "        cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
        "        spk2, mem2 = self.lif2(cur2, mem2)\n",
        "        cur3 = F.max_pool2d(self.conv3(spk2), 2)\n",
        "        spk3, mem3 = self.lif3(cur3, mem3)\n",
        "        return spk3.view(BATCH_SIZE, -1).shape[-1]\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.mem1 = self.lif1.init_leaky()\n",
        "        self.mem2 = self.lif2.init_leaky()\n",
        "        self.mem3 = self.lif3.init_leaky()\n",
        "        self.mem4 = self.lif4.init_leaky()\n",
        "\n",
        "    def forward(self, x):\n",
        "        cur1 = F.max_pool2d(self.conv1(x), 2)\n",
        "        spk1, self.mem1 = self.lif1(cur1, self.mem1)\n",
        "        cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
        "        spk2, self.mem2 = self.lif2(cur2, self.mem2)\n",
        "        cur3 = F.max_pool2d(self.conv3(spk2), 2)\n",
        "        spk3, self.mem3 = self.lif3(cur3, self.mem3)\n",
        "        output = self.output(spk3.view(spk3.shape[0], -1))\n",
        "        spk4, self.mem4 = self.lif4(output, self.mem4)\n",
        "        return spk4"
      ],
      "metadata": {
        "id": "qv4s0rurRwMW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_rate(input):\n",
        "    '''\n",
        "    Encodes input data into spike trains using rate coding.\n",
        "\n",
        "    Parameters:\n",
        "    input (torch.Tensor): Input tensor to be encoded.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: Rate-encoded spike train.\n",
        "    '''\n",
        "    return spikegen.rate(input, num_steps=NUM_STEPS, gain=GAIN)\n",
        "\n",
        "def encode_time(input):\n",
        "    '''\n",
        "    Encodes input data into spike trains using time-to-first-spike (latency) coding.\n",
        "\n",
        "    Parameters:\n",
        "    input (torch.Tensor): Input tensor to be encoded.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: Time-encoded spike train.\n",
        "    '''\n",
        "    return spikegen.latency(input, num_steps=NUM_STEPS, tau=TAU, threshold=THRESHOLD_LATENCY)\n",
        "\n",
        "def encode_delta(input):\n",
        "    '''\n",
        "    Encodes input data using delta modulation, based on changes in rate-coded spikes.\n",
        "\n",
        "    Parameters:\n",
        "    input (torch.Tensor): Input tensor to be encoded.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: Delta-encoded spike train.\n",
        "    '''\n",
        "    return spikegen.delta(spikegen.rate(input, num_steps=NUM_STEPS, gain=GAIN), threshold=THRESHOLD_DELTA, off_spike=True)"
      ],
      "metadata": {
        "id": "CS1foXxGR4Ju"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio Application"
      ],
      "metadata": {
        "id": "aDTr4AF5O4vx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "3-HKTkwRNy57",
        "outputId": "58a28775-5db5-4a78-c3a8-73fe0806ca0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7109dcfdf0fb405263.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7109dcfdf0fb405263.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Load the models\n",
        "model_rate = Neuromorphic_Net(images.shape, NUM_CLASSES)\n",
        "model_delta = Neuromorphic_Net(images.shape, NUM_CLASSES)\n",
        "model_time = Neuromorphic_Net(images.shape, NUM_CLASSES)\n",
        "\n",
        "model_rate.load_state_dict(torch.load(\"neuromorphic_rate_model.pth\", weights_only=False))\n",
        "model_delta.load_state_dict(torch.load(\"neuromorphic_delta_model.pth\", weights_only=False))\n",
        "model_time.load_state_dict(torch.load(\"neuromorphic_temporal_model.pth\", weights_only=False))\n",
        "\n",
        "# Select a random image and label\n",
        "def select_random_example():\n",
        "    index = random.randint(0, len(testset) - 1)\n",
        "    img, label = testset[index]\n",
        "    return img, label\n",
        "\n",
        "# Encode, visualize, and process the image\n",
        "def encode_and_visualize(encoding_method):\n",
        "    img, label = select_random_example()\n",
        "    img = img.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Select encoding method and model\n",
        "    if encoding_method == \"Rate Encoding\":\n",
        "        spike_data = encode_rate(img)\n",
        "        model = model_rate\n",
        "    elif encoding_method == \"Time-to-First-Spike Encoding\":\n",
        "        spike_data = encode_time(img)\n",
        "        model = model_time\n",
        "    elif encoding_method == \"Delta Encoding\":\n",
        "        spike_data = encode_delta(img)\n",
        "        model = model_delta\n",
        "\n",
        "    # Visualize the spike train\n",
        "    spike_data_sample = spike_data[:, 0, 0]\n",
        "    fig, ax = plt.subplots()\n",
        "    anim = splt.animator(spike_data_sample, fig, ax)\n",
        "\n",
        "    # Save animation as a video file\n",
        "    temp_video_path = os.path.join(tempfile.gettempdir(), \"spike_animation.mp4\")\n",
        "    anim.save(temp_video_path, writer=\"ffmpeg\", fps=10)\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Get model output\n",
        "    model.reset_states()\n",
        "    outputs = []\n",
        "    for step in spike_data:\n",
        "        output_step = model(step)\n",
        "        outputs.append(output_step)\n",
        "    outputs = torch.stack(outputs)\n",
        "    predicted_label = torch.argmax(outputs[-1], dim=1)\n",
        "\n",
        "    return temp_video_path, f\"Predicted: {predicted_label.item()}\", f\"Expected: {label}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=encode_and_visualize,\n",
        "    inputs=gr.Dropdown([\"Rate Encoding\", \"Time-to-First-Spike Encoding\", \"Delta Encoding\"], label=\"Choose Encoding Method\"),\n",
        "    outputs=[\n",
        "        gr.Video(label=\"Spike Train Animation\"),\n",
        "        gr.Textbox(label=\"Model Prediction\"),\n",
        "        gr.Textbox(label=\"Expected Label\"),\n",
        "    ],\n",
        "    title=\"🧠 Spiking Neural Network Visualization\",\n",
        "    description=(\n",
        "        \"This app demonstrates how a Spiking Neural Network (SNN) processes images using different encoding methods. \"\n",
        "        \"Select an encoding method, and the app will convert a random test image into a spike train, \"\n",
        "        \"visualize it, and use a trained SNN to classify the image. The model's predicted class will be compared with the expected label.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ]
    }
  ]
}